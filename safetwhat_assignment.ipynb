{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cf039ec-7876-46d7-9d22-a376ecc058ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26a235bf-d769-425a-a6c7-3d31a2f84e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r\"C:\\Users\\ASUS\\Downloads\\ssd-mobilenet-v2-tensorflow2-fpnlite-320x320-v1\"\n",
    "detection_model = tf.saved_model.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19af16f4-2dff-4666-a87a-a510703e606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_MAP = {\n",
    "    1: 'person',\n",
    "    2: 'car',\n",
    "    3: 'tree',\n",
    "    4: 'road',\n",
    "    5: 'road_sign',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a464436c-4060-4dcd-993b-9c482afb1a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(model, image_np):\n",
    "    input_tensor = tf.convert_to_tensor(image_np)\n",
    "    input_tensor = input_tensor[tf.newaxis,...]\n",
    "    \n",
    "    model_fn = model.signatures['serving_default']\n",
    "    output_dict = model_fn(input_tensor)\n",
    "    \n",
    "    return {key:value.numpy() for key,value in output_dict.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed851f9d-a5e4-4180-b241-c0bcb4521ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def associate_objects_and_subobjects(detection_boxes, detection_classes, detection_scores):\n",
    "    objects = []\n",
    "    sub_objects = []\n",
    "    object_counter = 1\n",
    "    sub_object_counter = 1\n",
    "\n",
    "    for i in range(len(detection_boxes)):\n",
    "        if detection_scores[i] > 0.5:  \n",
    "            object_class = LABEL_MAP.get(int(detection_classes[i]), 'Unknown')\n",
    "            bbox = detection_boxes[i]\n",
    "\n",
    "            obj = {\n",
    "                \"object\": object_class,\n",
    "                \"id\": object_counter,\n",
    "                \"bbox\": [float(coord) for coord in bbox],\n",
    "            }\n",
    "\n",
    "            if object_class == 'road_sign':\n",
    "                sub_obj = {\n",
    "                    \"object\": \"road_sign_details\",\n",
    "                    \"id\": sub_object_counter,\n",
    "                    \"bbox\": [bbox[0] + 0.1, bbox[1] + 0.1, bbox[2] - 0.1, bbox[3] - 0.1],  \n",
    "                }\n",
    "                sub_objects.append(sub_obj)\n",
    "                obj[\"subobject\"] = sub_obj\n",
    "                sub_object_counter += 1\n",
    "\n",
    "            objects.append(obj)\n",
    "            object_counter += 1\n",
    "\n",
    "    return objects, sub_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30a75361-b3cd-483c-b2b1-4b0543e18357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    print(f\"Video FPS: {fps}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    frame_count = 0\n",
    "    detections = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        image_np = cv2.resize(frame, (320, 320))\n",
    "        output = run_inference(detection_model, image_np)\n",
    "\n",
    "        detection_boxes = output['detection_boxes'][0]\n",
    "        detection_classes = output['detection_classes'][0]\n",
    "        detection_scores = output['detection_scores'][0]\n",
    "\n",
    "        objects, sub_objects = associate_objects_and_subobjects(detection_boxes, detection_classes, detection_scores)\n",
    "\n",
    "        for obj in objects:\n",
    "            detections.append(obj)\n",
    "            if \"subobject\" in obj:\n",
    "                for sub_obj in obj[\"subobject\"]:\n",
    "                    subobject_image_path = save_subobject_image(frame, sub_obj[\"bbox\"], sub_obj[\"id\"])\n",
    "                    print(f\"Sub-object image saved at: {subobject_image_path}\")\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    print(f\"Processed {frame_count} frames in {total_time} seconds.\")\n",
    "    print(f\"Frames per second: {frame_count / total_time}\")\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    with open('detections.json', 'w') as json_file:\n",
    "        json.dump(detections, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bc5bd18-425a-4755-aa4f-1825e46d14b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video FPS: 25.0\n",
      "Processed 750 frames in 255.54204392433167 seconds.\n",
      "Frames per second: 2.9349377835534645\n"
     ]
    }
   ],
   "source": [
    "video_path = r\"C:\\Users\\ASUS\\Downloads\\Traffic IP Camera video - Tech Channel00001 (720p, h264).mp4\"\n",
    "process_video(video_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
